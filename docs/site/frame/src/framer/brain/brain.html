<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>frame.src.framer.brain.brain API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>frame.src.framer.brain.brain</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="frame.src.framer.brain.brain.Brain"><code class="flex name class">
<span>class <span class="ident">Brain</span></span>
<span>(</span><span>llm_service: <a title="frame.src.services.llm.main.LLMService" href="../../services/llm/main.html#frame.src.services.llm.main.LLMService">LLMService</a>, execution_context: Optional[<a title="frame.src.services.context.execution_context_service.ExecutionContext" href="../../services/context/execution_context_service.html#frame.src.services.context.execution_context_service.ExecutionContext">ExecutionContext</a>] = None, memory_service: Optional[ForwardRef('MemoryService')] = None, roles: List[Dict[str, Any]] = [], goals: List[Dict[str, Any]] = [], default_model: str = 'gpt-3.5-turbo', soul: Optional[<a title="frame.src.framer.soul.soul.Soul" href="../soul/soul.html#frame.src.framer.soul.soul.Soul">Soul</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>The Brain class represents the central decision-making and cognitive processing component of the Framer.</p>
<p>Note: Plugins are lazily loaded. If a plugin does not have the necessary permissions, it will not be loaded until explicitly added with the required permissions.</p>
<p>It is responsible for processing perceptions, making decisions, and executing actions based on those decisions.
The Brain integrates various cognitive functions, including perception processing, decision-making,
memory management, and action execution.</p>
<p>Key features:
- Perception processing: Analyzes and interprets incoming perceptions.
- Decision-making: Generates decisions based on current context, roles, goals, and perceptions.
- Action execution: Executes decided actions using the action registry.
- Memory integration: Utilizes the memory service for storing and retrieving information.
- LLM integration: Uses language models for generating responses and making decisions.
- Role and goal management: Considers active roles and goals in the decision-making process.</p>
<p>The Brain uses a set of valid actions, derived from the ActionRegistry and default actions,
to determine which actions can be executed. This ensures that all actions are within the
defined capabilities of the Framer.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>llm_service</code></strong> :&ensp;<code>LLMService</code></dt>
<dd>The language model service for text generation and processing.</dd>
<dt><strong><code>default_model</code></strong> :&ensp;<code>str</code></dt>
<dd>The default language model to use.</dd>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>List of roles for the Brain.</dd>
<dt><strong><code>goals</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>List of goals for the Brain.</dd>
<dt><strong><code>soul</code></strong> :&ensp;<code>Optional[Soul]</code></dt>
<dd>The Soul instance associated with this Brain.</dd>
<dt><strong><code>execution_context</code></strong> :&ensp;<code>Optional[ExecutionContext]</code></dt>
<dd>The execution context for the Brain.</dd>
<dt><strong><code>mind</code></strong> :&ensp;<code>Mind</code></dt>
<dd>The Mind instance for cognitive processing.</dd>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service for storing and retrieving information.</dd>
<dt><strong><code>action_registry</code></strong> :&ensp;<code>ActionRegistry</code></dt>
<dd>Registry of available actions.</dd>
</dl>
<p>The Brain class serves as the cognitive core of the Framer, coordinating various components
to enable intelligent decision-making and action execution.</p>
<p>Execute the decision made by the brain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>decision</code></strong> :&ensp;<code>Decision</code></dt>
<dd>The decision to execute.</dd>
<dt><strong><code>perception</code></strong> :&ensp;<code>Optional[Perception]</code></dt>
<dd>The perception that led to this decision.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Before execution, this method validates the parameters associated with the
action to ensure they are correct and complete. If invalid parameters are
found, the execution may be halted or adjusted accordingly.
Make a decision on what action to take next based on the current state and perception.</p>
<h2 id="args_1">Args</h2>
<dl>
<dt><strong><code>perception</code></strong> :&ensp;<code>Optional[Perception]</code></dt>
<dd>The current perception of the environment.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Decision</code></dt>
<dd>The decision made based on the current state and perception,
including the action to take, parameters, reasoning, confidence,
and priority.</dd>
</dl>
<h2 id="notes_1">Notes</h2>
<p>This method now includes validation of variables and parameters to ensure
the decision can be executed properly. Invalid parameters are identified,
and appropriate actions are taken to handle them, such as adjusting the
decision or requesting additional information.
Initialize the Brain with the necessary components.</p>
<h2 id="args_2">Args</h2>
<dl>
<dt><strong><code>llm_service</code></strong> :&ensp;<code>LLMService</code></dt>
<dd>The language model service.</dd>
<dt>execution_context (Optional['ExecutionContext']): The execution context.</dt>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service.</dd>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>Initial roles for the Brain.</dd>
<dt><strong><code>goals</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>Initial goals for the Brain.</dd>
<dt><strong><code>default_model</code></strong> :&ensp;<code>str</code></dt>
<dd>The default language model to use.</dd>
<dt><strong><code>soul</code></strong> :&ensp;<code>Optional[Soul]</code></dt>
<dd>The Soul instance for the Brain.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Brain:
    &#34;&#34;&#34;
    The Brain class represents the central decision-making and cognitive processing component of the Framer.
    
    Note: Plugins are lazily loaded. If a plugin does not have the necessary permissions, it will not be loaded until explicitly added with the required permissions.

    It is responsible for processing perceptions, making decisions, and executing actions based on those decisions.
    The Brain integrates various cognitive functions, including perception processing, decision-making,
    memory management, and action execution.

    Key features:
    - Perception processing: Analyzes and interprets incoming perceptions.
    - Decision-making: Generates decisions based on current context, roles, goals, and perceptions.
    - Action execution: Executes decided actions using the action registry.
    - Memory integration: Utilizes the memory service for storing and retrieving information.
    - LLM integration: Uses language models for generating responses and making decisions.
    - Role and goal management: Considers active roles and goals in the decision-making process.

    The Brain uses a set of valid actions, derived from the ActionRegistry and default actions,
    to determine which actions can be executed. This ensures that all actions are within the
    defined capabilities of the Framer.

    Attributes:
        llm_service (LLMService): The language model service for text generation and processing.
        default_model (str): The default language model to use.
        roles (List[Dict[str, Any]]): List of roles for the Brain.
        goals (List[Dict[str, Any]]): List of goals for the Brain.
        soul (Optional[Soul]): The Soul instance associated with this Brain.
        execution_context (Optional[ExecutionContext]): The execution context for the Brain.
        mind (Mind): The Mind instance for cognitive processing.
        memory_service (Optional[MemoryService]): The memory service for storing and retrieving information.
        action_registry (ActionRegistry): Registry of available actions.

    The Brain class serves as the cognitive core of the Framer, coordinating various components
    to enable intelligent decision-making and action execution.
    &#34;&#34;&#34;

    def __init__(
        self,
        llm_service: LLMService,
        execution_context: Optional[ExecutionContext] = None,
        memory_service: Optional[&#34;MemoryService&#34;] = None,
        roles: List[Dict[str, Any]] = [],
        goals: List[Dict[str, Any]] = [],
        default_model: str = &#34;gpt-3.5-turbo&#34;,
        soul: Optional[Soul] = None,
    ) -&gt; Decision:
        &#34;&#34;&#34;
        Execute the decision made by the brain.

        Args:
            decision (Decision): The decision to execute.
            perception (Optional[Perception]): The perception that led to this decision.

        Notes:
            Before execution, this method validates the parameters associated with the
            action to ensure they are correct and complete. If invalid parameters are
            found, the execution may be halted or adjusted accordingly.
        Make a decision on what action to take next based on the current state and perception.

        Args:
            perception (Optional[Perception]): The current perception of the environment.

        Returns:
            Decision: The decision made based on the current state and perception,
                      including the action to take, parameters, reasoning, confidence,
                      and priority.

        Notes:
            This method now includes validation of variables and parameters to ensure
            the decision can be executed properly. Invalid parameters are identified,
            and appropriate actions are taken to handle them, such as adjusting the
            decision or requesting additional information.
        Initialize the Brain with the necessary components.

        Args:
            llm_service (LLMService): The language model service.
            execution_context (Optional[&#39;ExecutionContext&#39;]): The execution context.
            memory_service (Optional[MemoryService]): The memory service.
            roles (List[Dict[str, Any]]): Initial roles for the Brain.
            goals (List[Dict[str, Any]]): Initial goals for the Brain.
            default_model (str): The default language model to use.
            soul (Optional[Soul]): The Soul instance for the Brain.
        &#34;&#34;&#34;
        self.logger = logging.getLogger(__name__)
        self.llm_service = llm_service
        self.execution_context = execution_context or ExecutionContext(
            llm_service=self.llm_service, config=None
        )
        self.default_model = default_model
        self.roles = [
            Role(**role) if isinstance(role, dict) else role for role in roles
        ]
        self.goals = [
            Goal(**goal) if isinstance(goal, dict) else goal for goal in goals
        ]
        self.soul = soul
        self.memory_service = memory_service
        if self.memory_service:
            self.memory = Memory(self.memory_service)
        else:
            self.logger.warning(&#34;No memory service provided, Memory object not created&#34;)
            self.memory = None

        self.mind = Mind(self)
        self.action_registry = ActionRegistry(execution_context=self.execution_context)
        if not isinstance(self.execution_context, ExecutionContext):
            raise TypeError(&#34;execution_context must be an instance of ExecutionContext&#34;)

    def set_memory_service(self, memory_service: Optional[&#34;MemoryService&#34;]):
        &#34;&#34;&#34;
        Set the memory service for the Brain.

        Args:
            memory_service (Optional[MemoryService]): The memory service to set.
        &#34;&#34;&#34;
        self.memory_service = memory_service
        if self.memory_service:
            self.memory = Memory(self.memory_service)
            logger.info(f&#34;Set memory service: {self.memory_service}&#34;)
        else:
            self.memory = None
            logger.warning(
                &#34;Memory service is not set. Memory operations will not be available.&#34;
            )

    def set_framer(self, framer):
        self.framer = framer
        self.action_registry.set_execution_context(self.execution_context)

    def get_framer(self):
        return self.framer

    async def _execute_think_action(self, decision: &#34;Decision&#34;) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Execute the &#39;think&#39; action, which involves pondering on various aspects and potentially creating new tasks.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Dict[str, Any]: A dictionary containing the result of the think action, including:
                - analysis (str): Analysis of the current situation.
                - new_tasks (List[Dict[str, Any]]): List of new tasks if any.
                - generate_new_prompt (bool): Whether a new prompt should be generated.
                - new_prompt (str): The new prompt if generate_new_prompt is True.
        &#34;&#34;&#34;
        # Gather context for thinking
        soul_context = {}
        if (
            self.execution_context
            and hasattr(self.execution_context, &#34;soul&#34;)
            and self.execution_context.soul
        ):
            soul_context = self.execution_context.soul.get_current_state()

        roles_and_goals = {&#34;roles&#34;: self.roles, &#34;goals&#34;: self.goals}
        recent_thoughts = self.mind.get_all_thoughts()[-5:]  # Get last 5 thoughts
        recent_perceptions = self.mind.get_recent_perceptions(5)
        execution_state = self.execution_context.state if self.execution_context else {}
        # Prepare the prompt for the LLM
        prompt = f&#34;&#34;&#34;
        Based on the following context, ponder and reflect on the current situation:
        
        Soul state: {soul_context}
        Roles and goals: {roles_and_goals}
        Recent thoughts: {recent_thoughts}
        Recent perceptions: {recent_perceptions}

        Current decision: {decision.to_dict()}

        1. Analyze the current situation and provide insights.
        2. Determine if any new tasks or actions are necessary.
        3. If new tasks are needed, describe them in detail.
        4. Decide if a new prompt should be generated for better results.

        Respond with a JSON object containing the following fields:
        - analysis: Analysis of the current situation.
        - new_tasks: A list of new tasks if any (each task should have &#39;description&#39; and &#39;priority&#39;).
        - generate_new_prompt: A boolean indicating whether a new prompt should be generated.
        - new_prompt: The new prompt to use if generate_new_prompt is True.
        &#34;&#34;&#34;
        try:
            await self.llm_service.get_completion(
                prompt,
                model=self.default_model,
                expected_output=f&#34;&#34;&#34;
                {{
                    &#34;analysis&#34;: str,
                    &#34;new_tasks&#34;: list,
                    &#34;generate_new_prompt&#34;: bool,
                    &#34;new_prompt&#34;: str
                }}
                &#34;&#34;&#34;,
            )
        except Exception as e:
            logger.error(f&#34;Error in _execute_think_action: {str(e)}&#34;)
            return {&#34;error&#34;: str(e)}

    def parse_json_response(self, response: Any) -&gt; Any:
        &#34;&#34;&#34;
        Parse JSON response and handle potential errors.

        Args:
            response (Any): The response to parse, which could be a string or a dictionary.

        Returns:
            Any: The parsed JSON data or an error dictionary.
        &#34;&#34;&#34;
        if response is None:
            logger.error(&#34;Received None response, cannot parse JSON.&#34;)
            result = {
                &#34;action&#34;: &#34;error&#34;,
                &#34;parameters&#34;: {
                    &#34;error&#34;: &#34;Received None response&#34;,
                    &#34;raw_response&#34;: str(response),
                },
                &#34;reasoning&#34;: &#34;Failed to parse the decision data due to None response.&#34;,
                &#34;confidence&#34;: 0.0,
                &#34;priority&#34;: 1,
            }

        if isinstance(response, dict):
            # If response is already a dictionary, return it as is
            return response

        try:
            # If response is a string, try to parse it as JSON
            if isinstance(response, str):
                # Remove trailing commas from the response
                response = re.sub(r&#34;,\s*}&#34;, &#34;}&#34;, response)
                response = re.sub(r&#34;,\s*]&#34;, &#34;]&#34;, response)
                decision_data = json.loads(response)
            else:
                raise ValueError(f&#34;Unexpected response type: {type(response)}&#34;)

            # Ensure priority is a Priority enum
            priority_value = decision_data.get(&#34;priority&#34;, Priority.MEDIUM)
            try:
                decision_data[&#34;priority&#34;] = Priority.get(priority_value).value
            except (KeyError, ValueError) as e:
                logger.error(f&#34;Invalid priority: {priority_value}. Error: {e}&#34;)
                decision_data[&#34;priority&#34;] = Priority.MEDIUM.value
            return decision_data
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f&#34;Parsing error: {e}&#34;)
            logger.error(f&#34;Raw response: {response}&#34;)

            return {
                &#34;action&#34;: &#34;error&#34;,
                &#34;parameters&#34;: {
                    &#34;error&#34;: f&#34;Invalid response: {str(e)}&#34;,
                    &#34;raw_response&#34;: str(response),
                },
                &#34;reasoning&#34;: &#34;Failed to parse the decision data.&#34;,
                &#34;confidence&#34;: 0.0,
                &#34;priority&#34;: 1,
            }

    def set_roles(self, roles: List[&#34;Role&#34;]) -&gt; None:
        &#34;&#34;&#34;
        Set the roles for the Agency.

        Args:
            roles (List[Role]): List of Role objects to set.
        &#34;&#34;&#34;
        self.roles = roles
        self.execution_context.set_roles(roles)

    @log_execution
    @measure_performance
    async def process_perception(
        self,
        perception: Union[&#34;Perception&#34;, Dict[str, Any]],
        goals: Optional[List[&#34;Goal&#34;]] = None,
    ) -&gt; &#34;Decision&#34;:
        &#34;&#34;&#34;
        Process a perception and make a decision based on it.

        Args:
            perception (Union[&#39;Perception&#39;, Dict[str, Any]]): The perception to process.
            goals (Optional[List[Goal]]): List of Goal objects to set.

        Returns:
            Decision: The decision made based on the perception.
        &#34;&#34;&#34;

        if goals is not None:
            self.goals = goals
            self.execution_context.set_goals(goals)

        # Convert perception to Perception object if it is a dictionary
        if isinstance(perception, dict):
            perception = Perception.from_dict(perception)
        elif not isinstance(perception, Perception):
            raise TypeError(&#34;Perception must be a Perception object or a dictionary.&#34;)
        else:
            perception = Perception.from_dict(perception.to_dict())

        self.mind.perceptions.append(perception)
        available_actions = self.action_registry.get_all_actions().keys()
        self.logger.debug(f&#34;Processing perception: {perception}&#34;)
        self.logger.debug(f&#34;Avaliable actions: {available_actions}&#34;)
        decision = await self.make_decision(perception)
        if hasattr(self, &#34;framer&#34;) and getattr(self.framer, &#34;can_execute&#34;, False):
            if decision is None:
                self.logger.warning(&#34;No decision was made for the given perception.&#34;)
                return None
            if not decision.reasoning:
                decision.reasoning = (
                    &#34;Reasoning not provided. Encourage detailed reasoning.&#34;
                )
            # Check if the decision has already been executed
            if (
                not hasattr(self, &#34;_last_executed_decision&#34;)
                or self._last_executed_decision != decision
            ):
                await self.execute_decision(decision, perception)
                self._last_executed_decision = decision
            else:
                self.logger.info(
                    &#34;Decision has already been executed, skipping re-execution.&#34;
                )
        else:
            logger.warn(&#34;Framer is not ready to execute decisions. Queuing perception.&#34;)
            # Code to queue the perception can be added here if needed
        return decision

    async def make_decision(
        self, perception: Optional[Perception] = None
    ) -&gt; &#34;Decision&#34;:
        &#34;&#34;&#34;
        Make a decision on what action to take next based on the current state and perception.

        Args:
            perception (Optional[Perception]): The current perception of the environment.

        Returns:
            Decision: The decision made based on the current state and perception,
                      including the action to take, parameters, reasoning, confidence,
                      and priority.
        &#34;&#34;&#34;
        from frame.src.framer.brain.decision import Decision

        &#34;&#34;&#34;
        Make a decision on what action to take next based on the current state and perception.

        Args:
            perception (Optional[Perception]): The current perception of the environment.

        Returns:
            Decision: The decision made based on the current state and perception,
                      including the action to take, parameters, reasoning, confidence,
                      and priority.
        &#34;&#34;&#34;
        # If no perception is provided, return a default decision with no action
        if perception is None:
            return Decision(
                action=&#34;no_action&#34;,
                parameters={},
                reasoning=&#34;No perception provided&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        # Get a decision prompt based on the current perception
        response = await self._get_decision_prompt(perception)

        if response is None or (isinstance(response, str) and not response.strip()):
            logger.error(&#34;Received empty or None response from LLM service&#34;)
            return Decision(
                action=&#34;error&#34;,
                parameters={&#34;error&#34;: &#34;Empty or None response from LLM service&#34;},
                reasoning=&#34;Failed to get a valid response from the language model&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        # Parse the response from the LLM service to extract decision data
        decision_data = self.parse_json_response(response)

        logger.debug(f&#34;Decision data received: {decision_data}&#34;)

        if isinstance(decision_data, dict) and &#34;error&#34; in decision_data:
            logger.error(f&#34;Error in decision making: {decision_data[&#39;error&#39;]}&#34;)
            return Decision(
                action=&#34;error&#34;,
                parameters={&#34;error&#34;: decision_data[&#34;error&#34;]},
                reasoning=&#34;Error occurred during decision making&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        # Use default action &#39;respond&#39; if no action is provided
        try:
            action = decision_data.get(&#34;action&#34;, &#34;respond&#34;)
        except:
            action = &#34;no_action&#34;
        valid_actions = [
            str(action).lower()
            for action in self.action_registry.get_all_actions().keys()
        ]

        # Retrieve context from the execution context
        # If the context indicates high urgency and risk, choose an adaptive decision
        context = self.execution_context.get_full_state()
        # Determine the best action based on context
        if context.get(&#34;urgency&#34;, 0) &gt; 7 and context.get(&#34;risk&#34;, 0) &gt; 5:
            action = &#34;adaptive_decision&#34;
            decision_data[&#34;action&#34;] = action
            decision_data[&#34;reasoning&#34;] = (
                f&#34;High urgency and risk detected. Using &#39;{action}&#39; to adaptively decide the best course of action.&#34;
            )

        logger.info(f&#34;Decision made: {decision_data}&#34;)

        # Merge perception data into parameters
        parameters = decision_data.get(&#34;parameters&#34;, {})
        if not isinstance(parameters, dict):
            parameters = {}
        if perception and perception.data:
            # Ensure that perception data is considered
            parameters = {**perception.data, **parameters}

        reasoning = decision_data.get(&#34;reasoning&#34;, &#34;No reasoning provided.&#34;)

        # Check if goals are None and generate them if necessary
        # This ensures that the decision-making process has relevant goals to consider
        if self.execution_context and not self.execution_context.get_goals():
            # Assuming the execution_context has a method to generate goals
            goals = await self.execution_context.generate_goals()
            self.execution_context.set_goals(goals)

        # Consider role and goal priorities when setting decision priority
        # This helps in aligning the decision with the most critical roles and goals
        active_roles = [role for role in self.roles if role.status == RoleStatus.ACTIVE]
        active_goals = [
            goal
            for goal in self.execution_context.get_goals()
            if goal.status == GoalStatus.ACTIVE
        ]
        roles_priority = max(
            [role.priority for role in active_roles], default=Priority.MEDIUM
        )
        goals_priority = max(
            [goal.priority for goal in active_goals], default=Priority.MEDIUM
        )
        priority_value = None
        priority_int = None
        # Ensure priority is a Priority enum
        # Return the final decision object with all necessary attributes
        priority_value = decision_data.get(&#34;priority&#34;, Priority.MEDIUM)
        try:
            if isinstance(priority_value, str):
                priority_enum = Priority[priority_value.upper()]
            elif isinstance(priority_value, int):
                priority_enum = Priority(priority_value)
            elif isinstance(priority_value, Priority):
                priority_enum = priority_value
            else:
                raise ValueError(f&#34;Unexpected priority type: {type(priority_value)}&#34;)
        except (KeyError, ValueError) as e:
            logger.error(f&#34;Invalid priority: {priority_value}. Error: {e}&#34;)
            priority_enum = Priority.MEDIUM

        priority_int = priority_enum.value

        decision = Decision(
            action=action,
            parameters=parameters,
            reasoning=reasoning,
            confidence=float(decision_data.get(&#34;confidence&#34;, 0.5)),
            priority=priority_int,
            related_roles=[
                role for role in active_roles if role.priority &gt;= priority_int
            ],
            related_goals=[
                goal for goal in active_goals if goal.priority &gt;= priority_int
            ],
        )
        logger.info(f&#34;Final decision object: {decision}&#34;)
        logger.info(f&#34;Decision made: {decision}&#34;)
        if hasattr(decision, &#34;reasoning&#34;):
            decision.reasoning += f&#34; (Aligned with {len(active_goals)} active goals)&#34;
        else:
            logger.error(&#34;Decision object does not have a &#39;reasoning&#39; attribute.&#34;)
        print(&#34;Final decision object: &#34;, decision)
        # Convert related_roles and related_goals to Role and Goal instances
        related_roles = [
            role
            for role in active_roles
            if role.name in decision_data.get(&#34;related_roles&#34;, [])
        ]
        related_goals = [
            goal
            for goal in active_goals
            if goal.name in decision_data.get(&#34;related_goals&#34;, [])
        ]

        # Ensure parameters is a dictionary
        parameters = decision_data.get(&#34;parameters&#34;, {})
        if not isinstance(parameters, dict):
            parameters = {}
            
        # Ensure parameters is a dictionary
        if isinstance(decision_data.get(&#34;parameters&#34;), list):
            parameters = {}
        else:
            parameters = decision_data.get(&#34;parameters&#34;, {})
            if not isinstance(parameters, dict):
                parameters = {}

        # Ensure parameters includes the query and execution context for memory retrieval
        if decision_data.get(&#34;action&#34;) == &#34;respond with memory retrieval&#34;:
            parameters = {} if isinstance(parameters, list) else parameters
            if perception and perception.data:
                parameters.update({
                    &#34;query&#34;: perception.data.get(&#34;text&#34;, &#34;&#34;),
                    &#34;execution_context&#34;: self.execution_context,
                    &#34;llm_service&#34;: self.llm_service,
                })
                from frame.src.constants.user import DEFAULT_USER_ID
                parameters[&#34;user_id&#34;] = parameters.get(&#34;user_id&#34;, DEFAULT_USER_ID)

        decision = Decision(
            action=decision_data.get(&#34;action&#34;, &#34;respond&#34;),
            parameters=parameters,
            reasoning=decision_data.get(&#34;reasoning&#34;, &#34;No reasoning provided.&#34;),
            confidence=float(decision_data.get(&#34;confidence&#34;, 0.5)),
            priority=decision_data.get(&#34;priority&#34;, Priority.MEDIUM),
            related_roles=related_roles,
            related_goals=related_goals,
        )
        decision.result = decision.parameters.get(
            &#34;response_content&#34;, None
        )
        return decision

    async def _get_decision_prompt(self, perception: Optional[Perception]) -&gt; str:
        &#34;&#34;&#34;
        Generate a decision prompt based on the current perception and context.

        Args:
            perception (Optional[Perception]): The current perception.

        Returns:
            str: The generated decision prompt.
        &#34;&#34;&#34;
        valid_actions = self.action_registry.get_all_actions()
        logger.debug(f&#34;Valid actions: {valid_actions}&#34;)

        active_roles = [
            f&#34;{role.name} (Priority: {role.priority}, Status: {role.status.name})&#34;
            for role in self.roles
            if role.status == RoleStatus.ACTIVE
        ]
        active_goals = [
            f&#34;{goal.name} (Priority: {goal.priority}, Status: {goal.status.name})&#34;
            for goal in self.goals
            if goal.status == GoalStatus.ACTIVE
        ]

        prompt = f&#34;&#34;&#34;Given the following perception and context, decide on the most appropriate action to take.
        Perception: {perception}
        Perception Data: {perception.data}
        
        Current active roles:
        {json.dumps(active_roles, indent=2)}
        
        Current active goals:
        {json.dumps(active_goals, indent=2)}

        Valid actions are:
        {json.dumps({action_name: {&#34;description&#34;: action_info[&#34;description&#34;], &#34;expected_parameters&#34;: action_info.get(&#34;expected_parameters&#34;, []), &#34;priority&#34;: action_info[&#34;priority&#34;]} for action_name, action_info in self.action_registry.actions.items()}, indent=2)}
        
        For each perception, carefully evaluate:
        - The type and content of the perception
        - The urgency and importance of the information
        - The current active goals and roles of the system, considering their priorities and statuses
        - Whether immediate action, further research, or no action is most appropriate

        Examples of personal/memory questions (ALWAYS use &#39;respond with memory retrieval&#39; for these):
        - &#34;What is my favorite hobby?&#34; (contains &#34;my&#34; and asks about personal preference)
        - &#34;When is my next meeting?&#34; (contains &#34;my&#34; and asks about personal schedule)
        - &#34;What did I mention about...&#34; (contains &#34;I&#34; and refers to past conversation)

        Examples of general knowledge questions (Use &#39;respond&#39; for basic facts an AI would know):
        - &#34;What is the largest ocean on Earth?&#34; (basic geography)
        - &#34;How many planets are in the solar system?&#34; (basic science)
        - &#34;What is the boiling point of water?&#34; (common knowledge)
        - &#34;What is the capital of France?&#34; (basic geography)

        Only use &#39;research&#39; for complex topics requiring detailed investigation or verification, like:
        - &#34;What are the latest developments in quantum computing?&#34;
        - &#34;How has climate change affected migration patterns in Arctic birds?&#34;
        - &#34;What are the economic implications of recent policy changes?&#34;

        IMPORTANT: ONLY use &#39;respond with memory retrieval&#39; for questions that:
        1. Contain personal pronouns like &#34;my&#34;, &#34;I&#34;, &#34;we&#34;
        2. Ask about personal preferences, schedules, or past conversations
        3. Request information specific to the user

        For general knowledge, facts, or objective information, ALWAYS use &#39;respond&#39;.

        Priority levels and their meanings:
        from frame.src.framer.agency.priority import Priority

        {json.dumps({p.name: p.value for p in Priority}, indent=2)}

        Respond with a JSON object containing the following fields:
        - action: The action to take (must be EXACTLY one of the valid action names listed above)
        - parameters: Any relevant parameters for the action (e.g., new roles, goals, tasks, research topic, or response content)
        - reasoning: Your reasoning for this decision, including how it aligns with current roles and goals
        - confidence: A float between 0 and 1 indicating your confidence in this decision
        - priority: A string representing the priority level (e.g., &#34;LOW&#34;, &#34;MEDIUM&#34;, &#34;HIGH&#34;, &#34;CRITICAL&#34;) or an integer between 1 and 10 based on the urgency and importance of the action
        - related_roles: A list of role names that are most relevant to this decision
        - related_goals: A list of goal names that are most relevant to this decision

        Ensure your decision is well-reasoned, aligns with the current active goals and roles (considering their priorities), and uses only the valid actions provided.
        Use the provided priority levels when assigning priority to your decision, taking into account the priorities of related roles and goals.
        &#34;&#34;&#34;
        try:
            response = await self.llm_service.get_completion(
                prompt,
                model=self.default_model,
                additional_context={&#34;valid_actions&#34;: valid_actions},
                expected_output=f&#34;&#34;&#34;
                {{
                    &#34;action&#34;: str where str in {valid_actions},
                    &#34;parameters&#34;: dict,
                    &#34;reasoning&#34;: str,
                    &#34;confidence&#34;: float where 0 &lt;= float &lt;= 1,
                    &#34;priority&#34;: str,
                    &#34;related_roles&#34;: list,
                    &#34;related_goals&#34;: list
                }}
                &#34;&#34;&#34;,
            )
            if isinstance(response, dict) and &#34;error&#34; in response:
                logger.warning(f&#34;Error in LLM response: {response[&#39;error&#39;]}&#34;)
                return response
            return response
        except Exception as e:
            logger.error(f&#34;Error in _get_decision_prompt: {str(e)}&#34;)
            return {
                &#34;error&#34;: str(e),
                &#34;fallback_response&#34;: &#34;An error occurred while processing your request.&#34;,
            }

    async def execute_decision(
        self, decision: &#34;Decision&#34;, perception: Optional[Perception] = None
    ):
        from frame.src.framer.brain.decision import Decision

        &#34;&#34;&#34;
        Execute the decision made by the brain.

        Args:
            decision (Decision): The decision to execute.
            perception (Optional[Perception]): The perception that led to this decision.
        &#34;&#34;&#34;
        logger.debug(
            f&#34;Executing decision: {decision.action} with params {decision.parameters}&#34;
        )
        logger.debug(f&#34;Perception object: {perception}&#34;)
        # Handle different execution modes
        if decision.execution_mode == ExecutionMode.AUTO:
            # Execute the action immediately
            result = await self.action_registry.execute_action(
                decision.action, **decision.parameters
            )
            decision.result = result
            decision.status = DecisionStatus.EXECUTED

        elif decision.execution_mode == ExecutionMode.USER_APPROVAL:
            # Handle user approval logic
            decision.status = DecisionStatus.PENDING_APPROVAL
            # Optionally, queue the decision for approval

        elif decision.execution_mode == ExecutionMode.DEFERRED:
            # Handle deferred execution logic
            decision.status = DecisionStatus.DEFERRED
            # Optionally, schedule the decision for later execution

        else:
            # Default to not executing
            decision.status = DecisionStatus.NOT_EXECUTED

        # Return the decision object with the result and status
        return decision

    def _validate_parameters(
        self, action_name: str, parameters: Dict[str, Any]
    ) -&gt; bool:
        &#34;&#34;&#34;
        Validates that the given parameters match the expected format for the action.

        Args:
            action_name (str): The name of the action.
            parameters (Dict[str, Any]): The parameters to validate.

        Returns:
            bool: True if parameters are valid, False otherwise.

        Notes:
            This method checks whether all required parameters for the action are present
            and correctly formatted.
        &#34;&#34;&#34;
        # Validation logic...
        return True  # Placeholder for actual validation logic

    async def execute_action(
        self, action_name: str, parameters: Optional[dict] = None
    ) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Execute an action by its name using the action registry.&#34;&#34;&#34;
        if parameters is None:
            parameters = {}
        result = await self.action_registry.execute_action(action_name, **parameters)
        if isinstance(result, dict):
            result.setdefault(&#34;reasoning&#34;, None)
            result.setdefault(&#34;confidence&#34;, 0.5)
            result.setdefault(&#34;priority&#34;, 1)
            result.setdefault(&#34;related_roles&#34;, [])
            result.setdefault(&#34;related_goals&#34;, [])
            return result
        else:
            return {
                &#34;response&#34;: result,
                &#34;reasoning&#34;: &#34;No reasoning provided.&#34;,
                &#34;confidence&#34;: 0.5,
                &#34;priority&#34;: 1,
                &#34;related_roles&#34;: [],
                &#34;related_goals&#34;: [],
            }

    async def _execute_decision(self, decision: Decision) -&gt; Any:
        &#34;&#34;&#34;
        Execute the decision made by the brain.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Any: The result of executing the decision.
        &#34;&#34;&#34;
        logger.debug(f&#34;Executing decision: {decision.action}&#34;)
        logger.debug(f&#34;Decision parameters: {decision.parameters}&#34;)
        result = None
        try:
            # Pass priorities to the LLM to help prioritize tasks based on relevance
            for (
                action_name,
                action_info,
            ) in self.action_registry.get_all_actions().items():
                if action_name == decision.action:
                    if action_name == &#34;think&#34;:
                        result = await self._execute_think_action(decision)
                    elif action_name == &#34;respond&#34;:
                        result = await self.perform_task(
                            {
                                &#34;description&#34;: decision.parameters.get(&#34;content&#34;, &#34;&#34;),
                                &#34;workflow_id&#34;: &#34;default&#34;,
                            }
                        )
                    else:
                        print(f&#34;Executing action: {action_name}&#34;)
                        print(&#34;Action info: &#34;, action_info)
                        try:
                            result = await self.action_registry.execute_action(
                                action_name, decision.parameters
                            )
                        except Exception as e:
                            logger.error(f&#34;Error executing action &#39;{action_name}&#39;: {e}&#34;)
                            result = {
                                &#34;error&#34;: str(e),
                                &#34;fallback_response&#34;: &#34;An error occurred while processing your request. Please try again.&#34;,
                            }
                    break
            else:
                raise ValueError(f&#34;Action &#39;{decision.action}&#39; not found in registry.&#34;)

            logger.debug(f&#34;Executed action: {decision.action}&#34;)
            logger.debug(f&#34;Action result: {result}&#34;)
            logger.debug(f&#34;Decision reasoning: {decision.reasoning}&#34;)

        except Exception as e:
            logger.error(f&#34;Error executing decision: {e}&#34;)
            logger.exception(&#34;Detailed traceback:&#34;)
            result = {&#34;error&#34;: str(e)}

        return result

    async def _execute_think_action(self, decision: Decision):
        &#34;&#34;&#34;
        Execute the &#39;think&#39; action, which involves pondering on various aspects and potentially creating new tasks.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Any: The result of the think action.
        &#34;&#34;&#34;
        # Gather context for thinking
        soul_context = (
            self.execution_context.soul.get_current_state()
            if self.execution_context.soul
            else {}
        )
        roles_and_goals = {&#34;roles&#34;: self.roles, &#34;goals&#34;: self.goals}
        recent_thoughts = self.mind.get_all_thoughts()[-5:]  # Get last 5 thoughts
        recent_perceptions = self.mind.get_recent_perceptions(
            5
        )  # Use a fixed number instead of recent_perceptions_limit

        # Prepare the prompt for the LLM
        prompt = f&#34;&#34;&#34;
        Based on the following context, ponder and reflect on the current situation:

        Soul state: {soul_context}
        Roles and goals: {roles_and_goals}
        Recent thoughts: {recent_thoughts}
        Recent perceptions: {recent_perceptions}
        Execution state: {self.execution_context.state}

        Current decision: {decision.to_dict()}

        1. Analyze the current situation and provide insights.
        2. Determine if any new tasks or actions are necessary.
        3. If new tasks are needed, describe them in detail.
        4. Decide if a new prompt should be generated for better results.

        Respond with a JSON object containing:
        - analysis: Your analysis of the situation
        - new_tasks: A list of new tasks if any (each task should have &#39;description&#39; and &#39;priority&#39;)
        - generate_new_prompt: Boolean indicating if a new prompt should be generated
        - new_prompt: The new prompt if generate_new_prompt is true
        &#34;&#34;&#34;

        response = await self.llm_service.get_completion(
            prompt, model=self.default_model
        )
        result = json.loads(response)

        # Process the result
        self.mind.think(result[&#34;analysis&#34;])

        if result[&#34;new_tasks&#34;]:
            for task_data in result[&#34;new_tasks&#34;]:
                new_task = self.agency.create_task(**task_data)
                self.agency.add_task(new_task)

        if result[&#34;generate_new_prompt&#34;]:
            new_perception = Perception(
                type=&#34;thought&#34;, data={&#34;query&#34;: result[&#34;new_prompt&#34;]}
            )
            await self.process_perception(new_perception)

        return result

    async def _generate_new_query(self, decision: Decision) -&gt; str:
        &#34;&#34;&#34;
        Generate a new query based on the decision.

        Args:
            decision (Decision): The decision to base the new query on.

        Returns:
            str: The generated query.
        &#34;&#34;&#34;
        prompt = (
            f&#34;Based on the following decision, generate a new query or thought:\n\n&#34;
            f&#34;Decision: {decision.to_dict()}\n\nNew query:&#34;
        )
        response = await self.llm_service.get_completion(
            prompt, model=self.default_model
        )
        return response.strip()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="frame.src.framer.brain.brain.Brain.execute_action"><code class="name flex">
<span>async def <span class="ident">execute_action</span></span>(<span>self, action_name: str, parameters: Optional[dict] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Execute an action by its name using the action registry.</p></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.execute_decision"><code class="name flex">
<span>async def <span class="ident">execute_decision</span></span>(<span>self, decision: Decision, perception: Optional[<a title="frame.src.framer.brain.mind.perception.perception.Perception" href="mind/perception/perception.html#frame.src.framer.brain.mind.perception.perception.Perception">Perception</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.get_framer"><code class="name flex">
<span>def <span class="ident">get_framer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.make_decision"><code class="name flex">
<span>async def <span class="ident">make_decision</span></span>(<span>self, perception: Optional[<a title="frame.src.framer.brain.mind.perception.perception.Perception" href="mind/perception/perception.html#frame.src.framer.brain.mind.perception.perception.Perception">Perception</a>] = None) ‑> <a title="frame.src.models.framer.brain.decision.decision.Decision" href="../../models/framer/brain/decision/decision.html#frame.src.models.framer.brain.decision.decision.Decision">Decision</a></span>
</code></dt>
<dd>
<div class="desc"><p>Make a decision on what action to take next based on the current state and perception.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>perception</code></strong> :&ensp;<code>Optional[Perception]</code></dt>
<dd>The current perception of the environment.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Decision</code></dt>
<dd>The decision made based on the current state and perception,
including the action to take, parameters, reasoning, confidence,
and priority.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.parse_json_response"><code class="name flex">
<span>def <span class="ident">parse_json_response</span></span>(<span>self, response: Any) ‑> Any</span>
</code></dt>
<dd>
<div class="desc"><p>Parse JSON response and handle potential errors.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>response</code></strong> :&ensp;<code>Any</code></dt>
<dd>The response to parse, which could be a string or a dictionary.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Any</code></dt>
<dd>The parsed JSON data or an error dictionary.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.process_perception"><code class="name flex">
<span>async def <span class="ident">process_perception</span></span>(<span>self, perception: Union[ForwardRef('Perception'), Dict[str, Any]], goals: Optional[List[ForwardRef('Goal')]] = None) ‑> <a title="frame.src.models.framer.brain.decision.decision.Decision" href="../../models/framer/brain/decision/decision.html#frame.src.models.framer.brain.decision.decision.Decision">Decision</a></span>
</code></dt>
<dd>
<div class="desc"><p>Process a perception and make a decision based on it.</p>
<h2 id="args">Args</h2>
<dl>
<dt>perception (Union['Perception', Dict[str, Any]]): The perception to process.</dt>
<dt><strong><code>goals</code></strong> :&ensp;<code>Optional[List[Goal]]</code></dt>
<dd>List of Goal objects to set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Decision</code></dt>
<dd>The decision made based on the perception.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_framer"><code class="name flex">
<span>def <span class="ident">set_framer</span></span>(<span>self, framer)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_memory_service"><code class="name flex">
<span>def <span class="ident">set_memory_service</span></span>(<span>self, memory_service: Optional[ForwardRef('MemoryService')])</span>
</code></dt>
<dd>
<div class="desc"><p>Set the memory service for the Brain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service to set.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_roles"><code class="name flex">
<span>def <span class="ident">set_roles</span></span>(<span>self, roles: List[ForwardRef('Role')]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Set the roles for the Agency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Role]</code></dt>
<dd>List of Role objects to set.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="frame.src.framer.brain" href="index.html">frame.src.framer.brain</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="frame.src.framer.brain.brain.Brain" href="#frame.src.framer.brain.brain.Brain">Brain</a></code></h4>
<ul class="two-column">
<li><code><a title="frame.src.framer.brain.brain.Brain.execute_action" href="#frame.src.framer.brain.brain.Brain.execute_action">execute_action</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.execute_decision" href="#frame.src.framer.brain.brain.Brain.execute_decision">execute_decision</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.get_framer" href="#frame.src.framer.brain.brain.Brain.get_framer">get_framer</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.make_decision" href="#frame.src.framer.brain.brain.Brain.make_decision">make_decision</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.parse_json_response" href="#frame.src.framer.brain.brain.Brain.parse_json_response">parse_json_response</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.process_perception" href="#frame.src.framer.brain.brain.Brain.process_perception">process_perception</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_framer" href="#frame.src.framer.brain.brain.Brain.set_framer">set_framer</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_memory_service" href="#frame.src.framer.brain.brain.Brain.set_memory_service">set_memory_service</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_roles" href="#frame.src.framer.brain.brain.Brain.set_roles">set_roles</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>

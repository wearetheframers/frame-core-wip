<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>frame.src.framer.brain.brain API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>frame.src.framer.brain.brain</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="frame.src.framer.brain.brain.Brain"><code class="flex name class">
<span>class <span class="ident">Brain</span></span>
<span>(</span><span>llm_service: <a title="frame.src.services.llm.main.LLMService" href="../../services/llm/main.html#frame.src.services.llm.main.LLMService">LLMService</a>, execution_context: Optional[ForwardRef('ExecutionContext')] = None, memory_service: Optional[<a title="frame.src.services.memory.main.MemoryService" href="../../services/memory/main.html#frame.src.services.memory.main.MemoryService">MemoryService</a>] = None, roles: List[Dict[str, Any]] = [], goals: List[Dict[str, Any]] = [], default_model: str = 'gpt-3.5-turbo', soul: Optional[<a title="frame.src.framer.soul.soul.Soul" href="../soul/soul.html#frame.src.framer.soul.soul.Soul">Soul</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>The Brain class represents the central decision-making and cognitive processing component of the Framer.</p>
<p>It is responsible for processing perceptions, making decisions, and executing actions based on those decisions.
The Brain integrates various cognitive functions, including perception processing, decision-making,
memory management, and action execution.</p>
<p>Key features:
- Perception processing: Analyzes and interprets incoming perceptions.
- Decision-making: Generates decisions based on current context, roles, goals, and perceptions.
- Action execution: Executes decided actions using the action registry.
- Memory integration: Utilizes the memory service for storing and retrieving information.
- LLM integration: Uses language models for generating responses and making decisions.
- Role and goal management: Considers active roles and goals in the decision-making process.</p>
<p>The Brain uses a set of valid actions, derived from the ActionRegistry and default actions,
to determine which actions can be executed. This ensures that all actions are within the
defined capabilities of the Framer.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>llm_service</code></strong> :&ensp;<code>LLMService</code></dt>
<dd>The language model service for text generation and processing.</dd>
<dt><strong><code>default_model</code></strong> :&ensp;<code>str</code></dt>
<dd>The default language model to use.</dd>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>List of roles for the Brain.</dd>
<dt><strong><code>goals</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>List of goals for the Brain.</dd>
<dt><strong><code>soul</code></strong> :&ensp;<code>Optional[Soul]</code></dt>
<dd>The Soul instance associated with this Brain.</dd>
<dt><strong><code>execution_context</code></strong> :&ensp;<code>Optional[ExecutionContext]</code></dt>
<dd>The execution context for the Brain.</dd>
<dt><strong><code>mind</code></strong> :&ensp;<code>Mind</code></dt>
<dd>The Mind instance for cognitive processing.</dd>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service for storing and retrieving information.</dd>
<dt><strong><code>action_registry</code></strong> :&ensp;<code>ActionRegistry</code></dt>
<dd>Registry of available actions.</dd>
</dl>
<p>The Brain class serves as the cognitive core of the Framer, coordinating various components
to enable intelligent decision-making and action execution.</p>
<p>Initialize the Brain with the necessary components.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>llm_service</code></strong> :&ensp;<code>LLMService</code></dt>
<dd>The language model service.</dd>
<dt>execution_context (Optional['ExecutionContext']): The execution context.</dt>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service.</dd>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>Initial roles for the Brain.</dd>
<dt><strong><code>goals</code></strong> :&ensp;<code>List[Dict[str, Any]]</code></dt>
<dd>Initial goals for the Brain.</dd>
<dt><strong><code>default_model</code></strong> :&ensp;<code>str</code></dt>
<dd>The default language model to use.</dd>
<dt><strong><code>soul</code></strong> :&ensp;<code>Optional[Soul]</code></dt>
<dd>The Soul instance for the Brain.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Brain:

    &#34;&#34;&#34;
    The Brain class represents the central decision-making and cognitive processing component of the Framer.

    It is responsible for processing perceptions, making decisions, and executing actions based on those decisions.
    The Brain integrates various cognitive functions, including perception processing, decision-making,
    memory management, and action execution.

    Key features:
    - Perception processing: Analyzes and interprets incoming perceptions.
    - Decision-making: Generates decisions based on current context, roles, goals, and perceptions.
    - Action execution: Executes decided actions using the action registry.
    - Memory integration: Utilizes the memory service for storing and retrieving information.
    - LLM integration: Uses language models for generating responses and making decisions.
    - Role and goal management: Considers active roles and goals in the decision-making process.

    The Brain uses a set of valid actions, derived from the ActionRegistry and default actions,
    to determine which actions can be executed. This ensures that all actions are within the
    defined capabilities of the Framer.

    Attributes:
        llm_service (LLMService): The language model service for text generation and processing.
        default_model (str): The default language model to use.
        roles (List[Dict[str, Any]]): List of roles for the Brain.
        goals (List[Dict[str, Any]]): List of goals for the Brain.
        soul (Optional[Soul]): The Soul instance associated with this Brain.
        execution_context (Optional[ExecutionContext]): The execution context for the Brain.
        mind (Mind): The Mind instance for cognitive processing.
        memory_service (Optional[MemoryService]): The memory service for storing and retrieving information.
        action_registry (ActionRegistry): Registry of available actions.

    The Brain class serves as the cognitive core of the Framer, coordinating various components
    to enable intelligent decision-making and action execution.
    &#34;&#34;&#34;

    def __init__(
        self,
        llm_service: LLMService,
        execution_context: Optional[&#39;ExecutionContext&#39;] = None,
        memory_service: Optional[MemoryService] = None,
        roles: List[Dict[str, Any]] = [],
        goals: List[Dict[str, Any]] = [],
        default_model: str = &#34;gpt-3.5-turbo&#34;,
        soul: Optional[Soul] = None,
    ):
        &#34;&#34;&#34;
        Initialize the Brain with the necessary components.

        Args:
            llm_service (LLMService): The language model service.
            execution_context (Optional[&#39;ExecutionContext&#39;]): The execution context.
            memory_service (Optional[MemoryService]): The memory service.
            roles (List[Dict[str, Any]]): Initial roles for the Brain.
            goals (List[Dict[str, Any]]): Initial goals for the Brain.
            default_model (str): The default language model to use.
            soul (Optional[Soul]): The Soul instance for the Brain.
        &#34;&#34;&#34;
        self.logger = logging.getLogger(__name__)
        self.logger.info(&#34;Initializing Brain&#34;)
        self.llm_service = llm_service
        self.execution_context = execution_context or ExecutionContext(llm_service=self.llm_service)
        self.default_model = default_model
        self.roles = roles
        self.goals = goals
        self.soul = soul
        self.memory_service = memory_service
        self.logger.info(f&#34;Memory service received: {self.memory_service}&#34;)
        
        if self.memory_service:
            self.logger.info(&#34;Creating Memory object&#34;)
            self.memory = Memory(self.memory_service)
            self.logger.info(f&#34;Memory object created: {self.memory}&#34;)
        else:
            self.logger.warning(&#34;No memory service provided, Memory object not created&#34;)
            self.memory = None
        
        self.mind = Mind(self)
        # Initialize ActionRegistry
        self.action_registry = ActionRegistry(execution_context=self.execution_context)

        self.logger.info(f&#34;Brain initialized with memory service: {self.memory_service}&#34;)
        self.logger.info(f&#34;Brain memory object: {self.memory}&#34;)

    def set_memory_service(self, memory_service: Optional[&#39;MemoryService&#39;]):
        &#34;&#34;&#34;
        Set the memory service for the Brain.

        Args:
            memory_service (Optional[MemoryService]): The memory service to set.
        &#34;&#34;&#34;
        self.memory_service = memory_service
        if self.memory_service:
            self.memory = Memory(self.memory_service)
            logger.info(f&#34;Set memory service: {self.memory_service}&#34;)
        else:
            self.memory = None
            logger.warning(&#34;Memory service is not set. Memory operations will not be available.&#34;)

    def set_framer(self, framer):
        self.framer = framer

    def get_framer(self):
        return self.framer

    async def _execute_think_action(self, decision: Decision) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Execute the &#39;think&#39; action, which involves pondering on various aspects and potentially creating new tasks.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Dict[str, Any]: A dictionary containing the result of the think action, including:
                - analysis (str): Analysis of the current situation.
                - new_tasks (List[Dict[str, Any]]): List of new tasks if any.
                - generate_new_prompt (bool): Whether a new prompt should be generated.
                - new_prompt (str): The new prompt if generate_new_prompt is True.
        &#34;&#34;&#34;
        # Gather context for thinking
        soul_context = {}
        if (
            self.execution_context
            and hasattr(self.execution_context, &#34;soul&#34;)
            and self.execution_context.soul
        ):
            soul_context = self.execution_context.soul.get_current_state()

        roles_and_goals = {&#34;roles&#34;: self.roles, &#34;goals&#34;: self.goals}
        recent_thoughts = self.mind.get_all_thoughts()[-5:]  # Get last 5 thoughts
        recent_perceptions = self.mind.get_recent_perceptions(5)
        execution_state = self.execution_context.state if self.execution_context else {}

    def parse_json_response(self, response: Any) -&gt; Any:
        &#34;&#34;&#34;
        Parse JSON response and handle potential errors.

        Args:
            response (Any): The response to parse, which could be a string or a dictionary.

        Returns:
            Any: The parsed JSON data or an error dictionary.
        &#34;&#34;&#34;
        if response is None:
            logger.error(&#34;Received None response, cannot parse JSON.&#34;)
            return {
                &#34;action&#34;: &#34;error&#34;,
                &#34;parameters&#34;: {
                    &#34;error&#34;: &#34;Received None response&#34;,
                    &#34;raw_response&#34;: str(response),
                },
                &#34;reasoning&#34;: &#34;Failed to parse the decision data due to None response.&#34;,
                &#34;confidence&#34;: 0.0,
                &#34;priority&#34;: 1,
            }

        if isinstance(response, dict):
            # If response is already a dictionary, return it as is
            return response

        try:
            # If response is a string, try to parse it as JSON
            if isinstance(response, str):
                # Remove trailing commas from the response
                response = re.sub(r&#34;,\s*}&#34;, &#34;}&#34;, response)
                response = re.sub(r&#34;,\s*]&#34;, &#34;]&#34;, response)
                decision_data = json.loads(response)
            else:
                raise ValueError(f&#34;Unexpected response type: {type(response)}&#34;)

            # Ensure priority is a Priority enum
            priority_value = decision_data.get(&#34;priority&#34;, Priority.MEDIUM)
            try:
                decision_data[&#34;priority&#34;] = Priority.get(priority_value).value
            except (KeyError, ValueError) as e:
                logger.error(f&#34;Invalid priority: {priority_value}. Error: {e}&#34;)
                decision_data[&#34;priority&#34;] = Priority.MEDIUM.value
            return decision_data
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f&#34;Parsing error: {e}&#34;)
            logger.error(f&#34;Raw response: {response}&#34;)

            return {
                &#34;action&#34;: &#34;error&#34;,
                &#34;parameters&#34;: {
                    &#34;error&#34;: f&#34;Invalid response: {str(e)}&#34;,
                    &#34;raw_response&#34;: str(response),
                },
                &#34;reasoning&#34;: &#34;Failed to parse the decision data.&#34;,
                &#34;confidence&#34;: 0.0,
                &#34;priority&#34;: 1,
            }

    def set_roles(self, roles: List[Role]) -&gt; None:
        &#34;&#34;&#34;
        Set the roles for the Agency.

        Args:
            roles (List[Role]): List of Role objects to set.
        &#34;&#34;&#34;
        self.roles = roles
        self.execution_context.set_roles(roles)

    async def process_perception(
        self,
        perception: Union[&#39;Perception&#39;, Dict[str, Any]],
        goals: Optional[List[Goal]] = None,
    ) -&gt; &#39;Decision&#39;:
        &#34;&#34;&#34;
        Process a perception and make a decision based on it.

        Args:
            perception (Union[&#39;Perception&#39;, Dict[str, Any]]): The perception to process.
            goals (Optional[List[Goal]]): List of Goal objects to set.

        Returns:
            Decision: The decision made based on the perception.
        &#34;&#34;&#34;
        if goals is not None:
            self.goals = goals
            self.execution_context.set_goals(goals)

        # Convert perception to Perception object if it is a dictionary
        if isinstance(perception, dict):
            perception = Perception.from_dict(perception)

        self.mind.perceptions.append(perception)
        available_actions = self.action_registry.get_all_actions().keys()
        self.logger.debug(f&#34;Processing perception: {perception}&#34;)
        self.logger.debug(f&#34;Avaliable actions: {available_actions}&#34;)
        decision = await self.make_decision(perception)
        if hasattr(self, &#34;framer&#34;) and getattr(self.framer, &#34;can_execute&#34;, False):
            if decision is None:
                self.logger.warning(&#34;No decision was made for the given perception.&#34;)
                return None
            result = await self.execute_decision(decision, perception)
            return result
        else:
            logger.warn(&#34;Framer is not ready to execute decisions. Queuing perception.&#34;)
            # Code to queue the perception can be added here if needed
        return decision

    async def make_decision(self, perception: Optional[Perception] = None) -&gt; Decision:
        &#34;&#34;&#34;
        Make a decision on what action to take next based on the current state and perception.

        Args:
            perception (Optional[Perception]): The current perception of the environment.

        Returns:
            Decision: The decision made based on the current state and perception,
                      including the action to take, parameters, reasoning, confidence,
                      and priority.
        &#34;&#34;&#34;
        logger.info(f&#34;Making decision based on perception: {perception}&#34;)
        if perception is None:
            return Decision(
                action=&#34;no_action&#34;,
                parameters={},
                reasoning=&#34;No perception provided&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        response = await self._get_decision_prompt(perception)
        
        if response is None or (isinstance(response, str) and not response.strip()):
            logger.error(&#34;Received empty or None response from LLM service&#34;)
            return Decision(
                action=&#34;error&#34;,
                parameters={&#34;error&#34;: &#34;Empty or None response from LLM service&#34;},
                reasoning=&#34;Failed to get a valid response from the language model&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        decision_data = self.parse_json_response(response)

        logger.info(f&#34;Decision data received: {decision_data}&#34;)

        if isinstance(decision_data, dict) and &#34;error&#34; in decision_data:
            logger.error(f&#34;Error in decision making: {decision_data[&#39;error&#39;]}&#34;)
            return Decision(
                action=&#34;error&#34;,
                parameters={&#34;error&#34;: decision_data[&#39;error&#39;]},
                reasoning=&#34;Error occurred during decision making&#34;,
                confidence=0.0,
                priority=1,
                related_roles=[],
                related_goals=[],
            )

        action = decision_data.get(&#34;action&#34;, &#34;respond&#34;).lower()
        valid_actions = [
            str(action).lower()
            for action in self.action_registry.get_all_actions().keys()
        ]

        # Check if the action is valid
        if action not in valid_actions:
            # If the action is not valid, check if it&#39;s related to web search or summarization
            if any(keyword in action for keyword in [&#34;search&#34;, &#34;summarize&#34;, &#34;extract&#34;, &#34;memory&#34;]):
                action = &#34;respond with memory retrieval&#34;
                decision_data[&#34;action&#34;] = action
                decision_data[&#34;reasoning&#34;] = (
                    f&#34;Action &#39;{action}&#39; was generated based on the perception. &#34;
                    f&#34;Using the memory retrieval plugin to process this request.&#34;
                )
            else:
                invalid_action = action
                action = &#34;respond&#34;
                logger.warning(
                    f&#34;Invalid action &#39;{invalid_action}&#39; generated. &#34;
                    f&#34;Valid actions are: {&#39;, &#39;.join(valid_actions)}&#34;
                )
                decision_data[&#34;action&#34;] = action
                decision_data[&#34;reasoning&#34;] = (
                    f&#34;Invalid action &#39;{invalid_action}&#39; was generated. Defaulted to &#39;{action}&#39;.&#34;
                )

        logger.info(f&#34;Decision data generated: {decision_data}&#34;)
        logger.info(f&#34;Action &#39;{action}&#39; generated: {decision_data}&#34;)

        parameters = decision_data.get(&#34;parameters&#34;, {})
        if action == &#34;respond with memory retrieval&#34; and &#34;query&#34; not in parameters:
            parameters[&#34;query&#34;] = perception.data.get(&#34;text&#34;, &#34;&#34;)
        elif &#34;topic&#34; in parameters:
            parameters[&#34;research_topic&#34;] = parameters.pop(&#34;topic&#34;)
        if not isinstance(parameters, dict):
            parameters = {&#34;value&#34;: parameters}

        reasoning = decision_data.get(&#34;reasoning&#34;, &#34;No reasoning provided.&#34;)

        # Check if goals are None and generate them if necessary
        if self.execution_context and not self.execution_context.get_goals():
            # Assuming the execution_context has a method to generate goals
            goals = await self.execution_context.generate_goals()
            self.execution_context.set_goals(goals)

        # Consider role and goal priorities when setting decision priority
        active_roles = [role for role in self.roles if role.status == RoleStatus.ACTIVE]
        active_goals = [goal for goal in self.execution_context.get_goals() if goal.status == GoalStatus.ACTIVE]
        roles_priority = max(
            [role.priority for role in active_roles], default=Priority.MEDIUM
        )
        goals_priority = max(
            [goal.priority for goal in active_goals], default=Priority.MEDIUM
        )
        priority_value = None
        priority_int = None
        # Ensure priority is a Priority enum
        priority_value = decision_data.get(&#34;priority&#34;, Priority.MEDIUM)
        try:
            if isinstance(priority_value, str):
                priority_enum = Priority[priority_value.upper()]
            elif isinstance(priority_value, int):
                priority_enum = Priority(priority_value)
            elif isinstance(priority_value, Priority):
                priority_enum = priority_value
            else:
                raise ValueError(f&#34;Unexpected priority type: {type(priority_value)}&#34;)
        except (KeyError, ValueError) as e:
            logger.error(f&#34;Invalid priority: {priority_value}. Error: {e}&#34;)
            priority_enum = Priority.MEDIUM

        priority_int = priority_enum.value

        decision = Decision(
            action=action,
            parameters=parameters,
            reasoning=reasoning,
            confidence=float(decision_data.get(&#34;confidence&#34;, 0.5)),
            priority=priority_int,
            related_roles=[
                role for role in active_roles if role.priority &gt;= priority_int
            ],
            related_goals=[
                goal for goal in active_goals if goal.priority &gt;= priority_int
            ],
        )
        logger.info(f&#34;Final decision object: {decision}&#34;)
        logger.info(f&#34;Decision made: {decision}&#34;)
        if hasattr(decision, &#39;reasoning&#39;):
            decision.reasoning += f&#34; (Aligned with {len(active_goals)} active goals)&#34;
        else:
            logger.error(&#34;Decision object does not have a &#39;reasoning&#39; attribute.&#34;)
        return decision

    async def _get_decision_prompt(self, perception: Optional[Perception]) -&gt; str:
        &#34;&#34;&#34;
        Generate a decision prompt based on the current perception and context.

        Args:
            perception (Optional[Perception]): The current perception.

        Returns:
            str: The generated decision prompt.
        &#34;&#34;&#34;
        valid_actions = self.action_registry.valid_actions
        # action_descriptions = &#34;\n&#34;.join(
        #     [
        #         f&#34;- {name.lower()}: {info[&#39;description&#39;]}&#34;
        #         for name, info in self.agency.action_registry.actions.items()
        #     ]
        # )
        logger.info(f&#34;Valid actions: {valid_actions}&#34;)
        active_roles = [
            f&#34;{role.name} (Priority: {role.priority.name}, Status: {role.status.name})&#34;
            for role in self.roles
            if role.status == RoleStatus.ACTIVE
        ]
        active_goals = [
            f&#34;{goal.name} (Priority: {goal.priority.name}, Status: {goal.status.name})&#34;
            for goal in self.goals
            if goal.status == GoalStatus.ACTIVE
        ]

        # Log the actions being serialized
        # self.logger.info(f&#34;Serializing actions for decision prompt: {self.agency.action_registry.actions}&#34;)

        prompt = f&#34;&#34;&#34;Given the following perception and context, decide on the most appropriate action to take.
        Perception: {perception}
        
        Current active roles:
        {json.dumps(active_roles, indent=2)}
        
        Current active goals:
        {json.dumps(active_goals, indent=2)}

        Valid actions are:
        {json.dumps({str(action): f&#34;{self.action_registry.actions[action][&#39;description&#39;]} (Priority: {self.action_registry.actions[action][&#39;priority&#39;]})&#34; for action in self.action_registry.actions}, indent=2)}
        
        For each perception, carefully evaluate:
        - The type and content of the perception
        - The urgency and importance of the information
        - The current active goals and roles of the system, considering their priorities and statuses
        - Whether immediate action, further research, or no action is most appropriate

        Examples of personal/memory questions:
        - &#34;What is my favorite hobby?&#34;
        - &#34;When is my next meeting?&#34;
        - &#34;What did I mention about my travel plans?&#34;

        Examples of general knowledge questions:
        - &#34;What is the largest ocean on Earth?&#34;
        - &#34;How many planets are in the solar system?&#34;
        - &#34;What is the freezing point of water in Fahrenheit?&#34;

        General knowledge questions will have the regular action `respond`. Personal/memory questions will require memory retrieval and should use the `respond with memory retrieval` action.

        Priority levels and their meanings:
        {json.dumps({p.name: p.value for p in Priority}, indent=2)}

        Respond with a JSON object containing the following fields:
        - action: The action to take (must be EXACTLY one of the valid action names listed above)
        - parameters: Any relevant parameters for the action (e.g., new roles, goals, tasks, research topic, or response content)
        - reasoning: Your reasoning for this decision, including how it aligns with current roles and goals
        - confidence: A float between 0 and 1 indicating your confidence in this decision
        - priority: A string representing the priority level (e.g., &#34;LOW&#34;, &#34;MEDIUM&#34;, &#34;HIGH&#34;, &#34;CRITICAL&#34;) or an integer between 1 and 10 based on the urgency and importance of the action
        - related_roles: A list of role names that are most relevant to this decision
        - related_goals: A list of goal names that are most relevant to this decision

        Ensure your decision is well-reasoned, aligns with the current active goals and roles (considering their priorities), and uses only the valid actions provided.
        Use the provided priority levels when assigning priority to your decision, taking into account the priorities of related roles and goals.
        &#34;&#34;&#34;
        try:
            response = await self.llm_service.get_completion(
                prompt,
                model=self.default_model,
                additional_context={&#34;valid_actions&#34;: valid_actions},
                expected_output=f&#34;&#34;&#34;
                {{
                    &#34;action&#34;: str where str in {valid_actions},
                    &#34;parameters&#34;: dict,
                    &#34;reasoning&#34;: str,
                    &#34;confidence&#34;: float where 0 &lt;= float &lt;= 1,
                    &#34;priority&#34;: str,
                    &#34;related_roles&#34;: list,
                    &#34;related_goals&#34;: list
                }}
                &#34;&#34;&#34;,
            )
            if isinstance(response, dict) and &#34;error&#34; in response:
                logger.warning(f&#34;Error in LLM response: {response[&#39;error&#39;]}&#34;)
                return response
            return response
        except Exception as e:
            logger.error(f&#34;Error in _get_decision_prompt: {str(e)}&#34;)
            return {&#34;error&#34;: str(e), &#34;fallback_response&#34;: &#34;An error occurred while processing your request.&#34;}

    async def execute_decision(
        self, decision: Decision, perception: Optional[Perception] = None
    ):
        &#34;&#34;&#34;
        Execute the decision made by the brain.

        Args:
            decision (Decision): The decision to execute.
            perception (Optional[Perception]): The perception that led to this decision.
        &#34;&#34;&#34;
        logger.info(
            f&#34;Executing decision: {decision.action} with params {decision.parameters}&#34;
        )
        result = None
        try:
            if decision.action not in self.action_registry.get_all_actions():
                logger.error(f&#34;Action &#39;{decision.action}&#39; not found in registry.&#34;)
                return None

            if decision.action == &#34;respond with memory retrieval&#34;:
                if &#34;query&#34; not in decision.parameters or not decision.parameters[&#34;query&#34;]:
                    decision.parameters[&#34;query&#34;] = perception.data.get(&#34;text&#34;, &#34;&#34;) if perception else &#34;&#34;
                # Ensure the query is passed to the action
                result = await self.action_registry.execute_action(
                    decision.action, decision.parameters
                )
                return result
            elif decision.action == &#34;respond&#34;:
                # Use the execution_context to perform the task
                result = await self.execution_context.perform_task(
                    {
                        &#34;description&#34;: decision.parameters.get(&#34;content&#34;, &#34;&#34;),
                        &#34;workflow_id&#34;: &#34;default&#34;,
                    }
                )
            else:
                if decision.action == &#34;process_perception&#34; and &#34;perception&#34; not in decision.parameters:
                    decision.parameters[&#34;perception&#34;] = perception.data if perception else None

            result = await self.action_registry.execute_action(
                decision.action, decision.parameters
            )

            logger.info(f&#34;Action result: {result} with reasoning: {decision.reasoning}.&#34;)

        except Exception as e:
            logger.error(f&#34;Error executing decision: {e}&#34;)
            logger.exception(&#34;Detailed traceback:&#34;)
            result = {&#34;error&#34;: str(e)}

        return result

    async def execute_action(self, action_name: str, parameters: dict):
        &#34;&#34;&#34;Execute an action by its name using the action registry.&#34;&#34;&#34;
        return await self.action_registry.execute_action(action_name, parameters)

    async def _execute_decision(self, decision: Decision) -&gt; Any:
        &#34;&#34;&#34;
        Execute the decision made by the brain.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Any: The result of executing the decision.
        &#34;&#34;&#34;
        logger.debug(f&#34;Executing decision: {decision.action}&#34;)
        logger.debug(f&#34;Decision parameters: {decision.parameters}&#34;)
        result = None
        try:
            # Pass priorities to the LLM to help prioritize tasks based on relevance
            for (
                action_name,
                action_info,
            ) in self.action_registry.get_all_actions().items():
                if action_name == decision.action:
                    if action_name == &#34;think&#34;:
                        result = await self._execute_think_action(decision)
                    elif action_name == &#34;respond&#34;:
                        result = await self.perform_task(
                            {
                                &#34;description&#34;: decision.parameters.get(&#34;content&#34;, &#34;&#34;),
                                &#34;workflow_id&#34;: &#34;default&#34;,
                            }
                        )
                    else:
                        print(f&#34;Executing action: {action_name}&#34;)
                        print(&#34;Action info: &#34;, action_info)
                        try:
                            result = await self.action_registry.execute_action(
                                action_name, decision.parameters
                            )
                        except Exception as e:
                            logger.error(f&#34;Error executing action &#39;{action_name}&#39;: {e}&#34;)
                            result = {&#34;error&#34;: str(e), &#34;fallback_response&#34;: &#34;An error occurred while processing your request. Please try again.&#34;}
                    break
            else:
                raise ValueError(f&#34;Action &#39;{decision.action}&#39; not found in registry.&#34;)

            logger.info(f&#34;Executed action: {decision.action}&#34;)
            logger.debug(f&#34;Action result: {result}&#34;)
            logger.debug(f&#34;Decision reasoning: {decision.reasoning}&#34;)

        except Exception as e:
            logger.error(f&#34;Error executing decision: {e}&#34;)
            logger.exception(&#34;Detailed traceback:&#34;)
            result = {&#34;error&#34;: str(e)}

        return result


    async def _execute_think_action(self, decision: Decision):
        &#34;&#34;&#34;
        Execute the &#39;think&#39; action, which involves pondering on various aspects and potentially creating new tasks.

        Args:
            decision (Decision): The decision to execute.

        Returns:
            Any: The result of the think action.
        &#34;&#34;&#34;
        # Gather context for thinking
        soul_context = (
            self.execution_context.soul.get_current_state()
            if self.execution_context.soul
            else {}
        )
        roles_and_goals = {&#34;roles&#34;: self.roles, &#34;goals&#34;: self.goals}
        recent_thoughts = self.mind.get_all_thoughts()[-5:]  # Get last 5 thoughts
        recent_perceptions = self.mind.get_recent_perceptions(
            5
        )  # Use a fixed number instead of recent_perceptions_limit

        # Prepare the prompt for the LLM
        prompt = f&#34;&#34;&#34;
        Based on the following context, ponder and reflect on the current situation:

        Soul state: {soul_context}
        Roles and goals: {roles_and_goals}
        Recent thoughts: {recent_thoughts}
        Recent perceptions: {recent_perceptions}
        Execution state: {self.execution_context.state}

        Current decision: {decision.to_dict()}

        1. Analyze the current situation and provide insights.
        2. Determine if any new tasks or actions are necessary.
        3. If new tasks are needed, describe them in detail.
        4. Decide if a new prompt should be generated for better results.

        Respond with a JSON object containing:
        - analysis: Your analysis of the situation
        - new_tasks: A list of new tasks if any (each task should have &#39;description&#39; and &#39;priority&#39;)
        - generate_new_prompt: Boolean indicating if a new prompt should be generated
        - new_prompt: The new prompt if generate_new_prompt is true
        &#34;&#34;&#34;

        response = await self.llm_service.get_completion(
            prompt, model=self.default_model
        )
        result = json.loads(response)

        # Process the result
        self.mind.think(result[&#34;analysis&#34;])

        if result[&#34;new_tasks&#34;]:
            for task_data in result[&#34;new_tasks&#34;]:
                new_task = self.agency.create_task(**task_data)
                self.agency.add_task(new_task)

        if result[&#34;generate_new_prompt&#34;]:
            new_perception = Perception(
                type=&#34;thought&#34;, data={&#34;query&#34;: result[&#34;new_prompt&#34;]}
            )
            await self.process_perception(new_perception)

        return result

    async def _generate_new_query(self, decision: Decision) -&gt; str:
        &#34;&#34;&#34;
        Generate a new query based on the decision.

        Args:
            decision (Decision): The decision to base the new query on.

        Returns:
            str: The generated query.
        &#34;&#34;&#34;
        prompt = (
            f&#34;Based on the following decision, generate a new query or thought:\n\n&#34;
            f&#34;Decision: {decision.to_dict()}\n\nNew query:&#34;
        )
        response = await self.llm_service.get_completion(
            prompt, model=self.default_model
        )
        return response.strip()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="frame.src.framer.brain.brain.Brain.execute_action"><code class="name flex">
<span>async def <span class="ident">execute_action</span></span>(<span>self, action_name: str, parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute an action by its name using the action registry.</p></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.execute_decision"><code class="name flex">
<span>async def <span class="ident">execute_decision</span></span>(<span>self, decision: <a title="frame.src.framer.brain.decision.decision.Decision" href="decision/decision.html#frame.src.framer.brain.decision.decision.Decision">Decision</a>, perception: Optional[<a title="frame.src.framer.brain.mind.perception.perception.Perception" href="mind/perception/perception.html#frame.src.framer.brain.mind.perception.perception.Perception">Perception</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute the decision made by the brain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>decision</code></strong> :&ensp;<code>Decision</code></dt>
<dd>The decision to execute.</dd>
<dt><strong><code>perception</code></strong> :&ensp;<code>Optional[Perception]</code></dt>
<dd>The perception that led to this decision.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.get_framer"><code class="name flex">
<span>def <span class="ident">get_framer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.make_decision"><code class="name flex">
<span>async def <span class="ident">make_decision</span></span>(<span>self, perception: Optional[<a title="frame.src.framer.brain.mind.perception.perception.Perception" href="mind/perception/perception.html#frame.src.framer.brain.mind.perception.perception.Perception">Perception</a>] = None) ‑> <a title="frame.src.framer.brain.decision.decision.Decision" href="decision/decision.html#frame.src.framer.brain.decision.decision.Decision">Decision</a></span>
</code></dt>
<dd>
<div class="desc"><p>Make a decision on what action to take next based on the current state and perception.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>perception</code></strong> :&ensp;<code>Optional[Perception]</code></dt>
<dd>The current perception of the environment.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Decision</code></dt>
<dd>The decision made based on the current state and perception,
including the action to take, parameters, reasoning, confidence,
and priority.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.parse_json_response"><code class="name flex">
<span>def <span class="ident">parse_json_response</span></span>(<span>self, response: Any) ‑> Any</span>
</code></dt>
<dd>
<div class="desc"><p>Parse JSON response and handle potential errors.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>response</code></strong> :&ensp;<code>Any</code></dt>
<dd>The response to parse, which could be a string or a dictionary.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Any</code></dt>
<dd>The parsed JSON data or an error dictionary.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.process_perception"><code class="name flex">
<span>async def <span class="ident">process_perception</span></span>(<span>self, perception: Union[ForwardRef('Perception'), Dict[str, Any]], goals: Optional[List[<a title="frame.src.framer.agency.goals.Goal" href="../agency/goals.html#frame.src.framer.agency.goals.Goal">Goal</a>]] = None) ‑> <a title="frame.src.framer.brain.decision.decision.Decision" href="decision/decision.html#frame.src.framer.brain.decision.decision.Decision">Decision</a></span>
</code></dt>
<dd>
<div class="desc"><p>Process a perception and make a decision based on it.</p>
<h2 id="args">Args</h2>
<dl>
<dt>perception (Union['Perception', Dict[str, Any]]): The perception to process.</dt>
<dt><strong><code>goals</code></strong> :&ensp;<code>Optional[List[Goal]]</code></dt>
<dd>List of Goal objects to set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Decision</code></dt>
<dd>The decision made based on the perception.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_framer"><code class="name flex">
<span>def <span class="ident">set_framer</span></span>(<span>self, framer)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_memory_service"><code class="name flex">
<span>def <span class="ident">set_memory_service</span></span>(<span>self, memory_service: Optional[ForwardRef('MemoryService')])</span>
</code></dt>
<dd>
<div class="desc"><p>Set the memory service for the Brain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>memory_service</code></strong> :&ensp;<code>Optional[MemoryService]</code></dt>
<dd>The memory service to set.</dd>
</dl></div>
</dd>
<dt id="frame.src.framer.brain.brain.Brain.set_roles"><code class="name flex">
<span>def <span class="ident">set_roles</span></span>(<span>self, roles: List[<a title="frame.src.framer.agency.roles.Role" href="../agency/roles.html#frame.src.framer.agency.roles.Role">Role</a>]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Set the roles for the Agency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>roles</code></strong> :&ensp;<code>List[Role]</code></dt>
<dd>List of Role objects to set.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="frame.src.framer.brain" href="index.html">frame.src.framer.brain</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="frame.src.framer.brain.brain.Brain" href="#frame.src.framer.brain.brain.Brain">Brain</a></code></h4>
<ul class="two-column">
<li><code><a title="frame.src.framer.brain.brain.Brain.execute_action" href="#frame.src.framer.brain.brain.Brain.execute_action">execute_action</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.execute_decision" href="#frame.src.framer.brain.brain.Brain.execute_decision">execute_decision</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.get_framer" href="#frame.src.framer.brain.brain.Brain.get_framer">get_framer</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.make_decision" href="#frame.src.framer.brain.brain.Brain.make_decision">make_decision</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.parse_json_response" href="#frame.src.framer.brain.brain.Brain.parse_json_response">parse_json_response</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.process_perception" href="#frame.src.framer.brain.brain.Brain.process_perception">process_perception</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_framer" href="#frame.src.framer.brain.brain.Brain.set_framer">set_framer</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_memory_service" href="#frame.src.framer.brain.brain.Brain.set_memory_service">set_memory_service</a></code></li>
<li><code><a title="frame.src.framer.brain.brain.Brain.set_roles" href="#frame.src.framer.brain.brain.Brain.set_roles">set_roles</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
